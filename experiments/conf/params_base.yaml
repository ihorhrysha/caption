# general
project_name: "image-captioning"
experiment_name: ""              # prefix of all artifacts ('' means None, create next name)
seed: 42                         # random seed
with_cuda: True                  # CUDA training
path_save: "experiments/logs"    # path to save all artifacts (models, checkpoints, logs)
new_folder: True                 # to handle all experiments in new folders
tyne_mode: False                 # hyperparam tuning

TRAIN:
  resume: ""
  epochs: 5
  optim: "adam"                   # support also "adam", "rmsprop"
  lr: 0.001                       # this is for "sgd" optimizer
  scheduler: ""            # "StepLR" or ""
  bleu_n: 3

MODEL:
  name: "resnet_152_lstm"        # could be 'resnet_152_lstm', 'vgg_bn_pre_in3x32x32_out10', 'vgg_bn_in3x32x32_out10'
  weights: ""                    #
  embed_size: 256
  hidden_size: 512
  num_layers: 1

DATASET:
  name: "flickr8k"
  path: "data/flickr8k/"
  batch_sizes:
    train: 128                # input batch size for training
    val: 128                  # input batch size for testing
  num_workers: 4
  transforms:
    tokenizer: "nltk" 
    threshold: 5
    train: "flickr8k"           
    val: "flickr8k_init"             
  tiny: True

LOG:
  iter_interval: 1     # how often (iter) display training details
  tensorboard: False
  wandb: 
    enable: True
    entity: "grego"
  do_checkpoint: False
